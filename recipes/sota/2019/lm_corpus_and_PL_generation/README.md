# Pseudo-Label Generation
Pseudo-labels can be generated by following the reproduction steps for the [Libri-Light Dataset](https://arxiv.org/abs/1912.07875) using the tools found in the [corresponding repository](https://github.com/facebookresearch/libri-light), but with some modifications. Note that these instructions work with commit [`9d798f92e15f8b6ba128a23b9dc2dc478a8bb5e2`](https://github.com/facebookresearch/libri-light/tree/9d798f92e15f8b6ba128a23b9dc2dc478a8bb5e2) and earlier.

### Creating the Unlabeled Audio Set

First, follow the steps to [download, unzip, and re-encode](https://github.com/facebookresearch/libri-light/tree/master/data_preparation#regenerating-the-dataset-from-scratch-or-with-books-in-another-language). After the raw is ready for processing, [run VAD on the resulting audio](https://github.com/facebookresearch/libri-light/tree/master/data_preparation#running-voice-activity-detection-and-snr-computation) as per the given instructions.

Audio segmentation occurs differently as a result of constraints on model architectures (i.e. the transformer). In particular, [run `cut_by_vad`](https://github.com/facebookresearch/libri-light/tree/master/data_preparation#1b-segmenting) but the `--target_len_sec` flag should be set as `15`.

The resulting segmentations will contain some samples longer than `36` seconds, which exceed the largest padable receptive field size for the transformer architectures. Utterances longer than 36 seconds must be removed.

## LM Corpus Reproduction

This document describes normalization of "no overlap" language model corpus, which contains the LibriSpeech LM corpus excluding any books that are contained in LibriVox audio used in the paper, details on corpus creation see in [`../raw_lm_corpus`](../raw_lm_corpus/README.md).

### Data Normalization (Librispeech LM data without Librivox)
```
git clone --recursive https://github.com/moses-smt/mosesdecoder.git && cd mosesdecoder && git checkout fd06cdf026dd9e0396db56a7d93c2f6b446a1e02 && cd ..
pip install num2words roman
source normalize.sh ../raw_lm_corpus/librispeech_lm_corpus.minus_librivox.metadata_and_manual_and_missing.corpus.txt
python3 generate_uniq.py librispeech_lm_corpus_raw_without_librivox.txt.norm
python3 generate_frequencies.py librispeech_lm_corpus_raw_without_librivox.txt.norm.unique
python3 generate_kenlm_vocab.py librispeech_lm_corpus_raw_without_librivox.txt.norm.unique.freq 200000 200k
```

### Train 4gram LM
```
KENLM=[...]/kenlm/build/bin
devclean=[DATA_PATH]/text/dev-clean.txt
devother=[DATA_PATH]/text/dev-other.txt

"$KENLM/lmplz" -T /tmp -S 100G --discount_fallback -o 4 \
    --limit_vocab_file librispeech_lm_corpus_raw_without_librivox.txt.norm.unique.freq.kenlm.200kvocab trie < librispeech_lm_corpus_raw_without_librivox.txt.norm.unique > nooverlap_librispeech_kenlm_4g_200kvocab.arpa
"$KENLM/build_binary" trie nooverlap_librispeech_kenlm_4g_200kvocab.arpa nooverlap_librispeech_kenlm_4g_200kvocab.bin
"$KENLM/query" nooverlap_librispeech_kenlm_4g_200kvocab.bin < "$devclean" > nooverlap_librispeech_kenlm_4g_200kvocab.bin.dev_clean
"$KENLM/query" nooverlap_librispeech_kenlm_4g_200kvocab.bin < "$devother" > nooverlap_librispeech_kenlm_4g_200kvocab.bin.dev_other
```

## Decoding with 4gram
Running random search with 128 tries over `lmweigth` and `wordscore` parameters with the same config as `decode_pl.cfg` (this config contains best params we found and this config is used to generate pseudo labels). Here we use our best transformer CTC model trained on Librispeech only.

Config `decode_pl_overlap.cfg` is used for ablation study (parameters are from the best config of `../librispeech/decode_transformer_ctc_dev_other.cfg`) - here we change only the language model. Decoding with train only lexicon is very similar to the decoding with 200k lexicon as in the `../librispeech/decode_transformer_ctc_dev_other.cfg`.

To run pseudo labels generation:
```
[...]/wav2letter/build/Decoder --flagsfile decode_pl.cfg --minloglevel=0 --logtostderr=1
```
for ablation study:
```
[...]/wav2letter/build/Decoder --flagsfile decode_pl_overlap.cfg --minloglevel=0 --logtostderr=1
```

We then prepare lists for training and place them to [DATA_DST_librilight]/lists/librivox.lst and [DATA_DST_librilight]/lists/librivox_overlap.lst respectively.

For ablation we also prepared randomly sampled lists of 1000 hour, 3000 hours, and 10000 hours. Each above subset has each smaller one as a subset; i.e. the 1000h set is a subset of the 3000h set, which is a subset of the 10000h set.


## Post Processing Output

First, extract hypotheses. From the `sclite` output directory. The blow code assumes inference was parallelized into `NUM_SPLITS` sets of audio samples and resulting outputs:

```
for i in {1..$NUM_SPLITS}; do \
    cat "[path to hyp file with index $i]" \
    | sed 's/ (.*//' | awk '{$1=$1};1'  \
    > ../postprocessing/$i.hyp; echo $i; done
```

Now, extract sample IDs:

```
for i in {1..$NUM_SPLITS}; do \
    cat "[path to hyp file with index $i]" \
    | sed "s/.*(//" | sed "s/).*//" | awk '{$1=$1};1'  \
    > ../postprocessing/$i.id; echo $i; done
```

Combine into a lookup table:

```
for i in {1..$NUM_SPLITS}; do paste -d " " $i.id $i.hyp > $i.table; echo $i; done
```

Combine and sort the tables:

```
cat postprocessing/*.table | sort -S 75% --parallel=$(nproc) > results.table
```

Join to create a final list file:

```
join -1 1 -2 1 \
    unlabeled/librivox.cut.sub36s.unlabeled.lst /\
    [path to data]/results.table | \
    sort -S 75% --parallel=$(nproc) \
    > librivox.cut.sub36s.[some lm].lst
```
