# Training config for Librispeech using Time-Depth Separable Convolutions
# Replace `[...]`, `[MODEL_DST]`, `[DATA_DST]`, `[DATA_DST_librilight] with appropriate paths
--runname=inference_2019
--rundir=[...]
--tokensdir=[MODEL_DST]/am
--archdir=[...]
--train=[DATA_DST]/lists/train-clean-100.lst,[DATA_DST]/lists/train-clean-360.lst,[DATA_DST]/lists/train-other-500.lst,[DATA_DST_librilight]/lists/librilight.lst
--valid=dev-clean:[DATA_DST]/lists/dev-clean.lst,dev-other:[DATA_DST]/lists/dev-other.lst
--lexicon=[MODEL_DST]/am/librispeech-train+dev-unigram-10000-nbest10.lexicon
--arch=am_500ms_future_context.arch
--tokens=librispeech-train-all-unigram-10000.tokens
--criterion=ctc
--batchsize=8
--lr=0.4
--momentum=0.0
--maxgradnorm=0.5
--reportiters=1000
--nthread=6
--mfsc=true
--usewordpiece=true
--wordseparator=_
--filterbanks=80
--minisz=200
--mintsz=2
--maxisz=33000
--enable_distributed=true
--pcttraineval=1
--minloglevel=0
--logtostderr
--onorm=target
--sqnorm
--localnrmlleftctx=300
--lr_decay=10000
